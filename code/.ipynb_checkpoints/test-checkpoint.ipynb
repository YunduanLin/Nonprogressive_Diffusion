{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f213ee-0cf3-478a-857f-d80fe5794d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tnrange,tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf44146d-7668-4a7c-af53-868b782fbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_simulation import diffusion_simulation\n",
    "from network import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2df734a-5ad1-404f-a993-2976b0579f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(sim_id, is_no0):\n",
    "    params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "          'noise_dist': 'logistic', 'noise_dist_param': 1,\n",
    "          'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "          'is_network_given':True, 'network_dir':f'../instances/{sim_id}/edge.csv',  \n",
    "          'is_value_given':True, 'value_dir':f'../instances/{sim_id}/v.csv'\n",
    "         }\n",
    "    G = network(params)\n",
    "    \n",
    "    df = pd.read_csv(f'../instances/{sim_id}/results.csv')\n",
    "\n",
    "    if is_no0:\n",
    "        is_not_0 = G.in_degree > 0\n",
    "    \n",
    "        if G.n<len(df):\n",
    "            df = df[:G.n]\n",
    "        df_1 = df[is_not_0]\n",
    "        mape = np.mean(np.abs(df_1['sim']-df_1['fp'])/df_1['sim'])\n",
    "        \n",
    "        G.cal_mean_inv_indeg()\n",
    "        pd.DataFrame({'n':[G.n], 'd_mean':[np.mean(G.in_degree)], 'inv_ind_density':[np.mean(1/G.in_degree[is_not_0])], \n",
    "                      'mape':[mape]}\n",
    "                    ).to_csv(f'../instances/{sim_id}/metrics_no0.csv', index=None)\n",
    "    else:\n",
    "        mape = np.mean(np.abs(df['sim']-df['fp'])/df['sim'])\n",
    "        \n",
    "        G.cal_mean_inv_indeg()\n",
    "        pd.DataFrame({'n':[G.n], 'd_min':[np.min(G.in_degree_adj)], 'd_max':[np.max(G.in_degree)], \n",
    "                     'd_mean':[np.mean(G.in_degree)], 'out_in_ratio': [np.max(G.out_degree)/max(np.min(G.in_degree),1)], \n",
    "                     'deg_corr':[np.corrcoef(G.in_degree, G.out_degree)[0,1]],\n",
    "                     'inv_ind_density':[G.ave_inv_indeg], \n",
    "                      'mape':[mape]}\n",
    "                    ).to_csv(f'../instances/{sim_id}/metrics.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b258fbcf-540a-4a7b-bd25-f8c5efc09619",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_density = {'1_n13': lambda n:1/n**1.3,\n",
    "                '1_n11': lambda n:1/n**1.1,\n",
    "                '1_n': lambda n:1/n, \n",
    "                'sqrtlogn_n': lambda n:np.sqrt(np.log(n))/n,\n",
    "                'logn_n': lambda n:np.log(n)/n, \n",
    "                'logn2_n': lambda n:np.log(n)**2/n,\n",
    "                '1': lambda n: 0.1}\n",
    "\n",
    "dict_real = {'caltech': 'Caltech36', \n",
    "             'reed': 'Reed98', \n",
    "             'haverford': 'Haverford76', \n",
    "             'simmons': 'Simmons81', \n",
    "             'amherst': 'Amherst41'}\n",
    "\n",
    "dict_alpha = {'25': 2.5,\n",
    "              '30': 3,\n",
    "              '35': 3.5}\n",
    "\n",
    "dict_theta = {'neg10': -1,\n",
    "              'neg05': -0.5,\n",
    "              'pos05': 0.5,\n",
    "              'pos10':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2d2cc2-098c-465e-963d-1dfd95c2d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = 1 # For illustration purposes, generate one repetition. To fully replicate the result in the paper, change this to 50.\n",
    "l_n = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000] # Network size\n",
    "l_pn1 = ['1_n11', '1_n', 'logn2_n', '1'] # ER Network density 1\n",
    "l_pn2 = ['1_n13', 'sqrtlogn_n', 'logn_n'] # ER Network density 2\n",
    "l_pn = ['1_n13', '1_n11', '1_n', 'sqrtlogn_n', 'logn_n', 'logn2_n', '1']\n",
    "l_alpha = ['25', '30', '35'] # PL Network exponent\n",
    "l_theta = ['neg05', 'pos05', 'neg10', 'pos10'] # PL Network correlation\n",
    "l_real = ['caltech', 'reed', 'haverford', 'simmons', 'amherst'] # Real-world network\n",
    "l_t_iter = [100, 1000] # Resample times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334b4d3-f55b-4cc9-88af-e8d4f057e4e5",
   "metadata": {},
   "source": [
    "## __Figure 3__: Performance of ER graph (with varying network size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53f2cb-5104-4dc2-8df2-8e44dfb8894b",
   "metadata": {},
   "source": [
    "### Generate one instance for each ER graph parameter pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dfa024-3b03-4ae9-8757-49877a2497fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance generated with 20 nodes.\n",
      "Instance generated with 50 nodes.\n",
      "Instance generated with 100 nodes.\n",
      "Instance generated with 200 nodes.\n",
      "Instance generated with 500 nodes.\n",
      "Instance generated with 1000 nodes.\n",
      "Instance generated with 2000 nodes.\n",
      "Instance generated with 5000 nodes.\n",
      "Instance generated with 10000 nodes.\n"
     ]
    }
   ],
   "source": [
    "for pn in l_pn1:\n",
    "    for n in l_n:\n",
    "        for i in range(1,rep+1):\n",
    "            sim_id = f'ER_{pn}/n{n}_{i}'\n",
    "            os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "            params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                      'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                      'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                      'network_type': 'ER',\n",
    "                      'is_network_given':False, 'network_size': n, 'ER_prob':dict_density[pn](n), 'network_dir':'',\n",
    "                      'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4, 'value_dir':''\n",
    "                     }\n",
    "            \n",
    "            G = network(params)\n",
    "            sample = diffusion_simulation(G,params)\n",
    "            sample.start_diffusion()\n",
    "            sample.run_fixed_point()\n",
    "            sample.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f6cdb-a631-4e3d-8d59-3a0ba753630e",
   "metadata": {},
   "source": [
    "### Calculate the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3923d8b-01c3-43e0-9834-735d46a43212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pn in l_pn1:\n",
    "    for n in l_n:\n",
    "        for i in range(1,rep+1):\n",
    "            print_metrics(f'ER_{pn}/n{n}_{i}', True)\n",
    "            print_metrics(f'ER_{pn}/n{n}_{i}', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a20fd2-5a92-45f2-8cfd-f255c3302846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_results = dict()\n",
    "\n",
    "for pn in l_pn1:\n",
    "    rec_mape, rec_inv_deg, rec_mean_inv = [], [], []\n",
    "    for n in l_n:\n",
    "        mape, inv_deg, mean_inv  = [], [], []\n",
    "        for i in range(1,rep+1):\n",
    "            df = pd.read_csv(f'../instances/ER_{pn}/n{n}_{i}/metrics_no0.csv')\n",
    "            mape.append(df['mape'].values[0]*100)\n",
    "            inv_deg.append(df['inv_ind_density'].values[0])\n",
    "            mean_inv.append(1/df['d_mean'].values[0])\n",
    "        rec_mape.append(mape)\n",
    "        rec_inv_deg.append(inv_deg)\n",
    "        rec_mean_inv.append(mean_inv)\n",
    "\n",
    "    dict_results[(pn,'mape')] = rec_mape\n",
    "    dict_results[(pn,'inv_deg')] = rec_inv_deg\n",
    "    dict_results[(pn,'mean_inv')] = rec_mean_inv\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d6f78-f5de-40d4-acf8-ae4877941581",
   "metadata": {},
   "source": [
    "### Replicate Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fddec4f-ac57-473c-8a25-74fe191a850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size\n",
    "plt.plot(l_n, np.mean(dict_results[('1_n11','mape')],axis=1), c='#8ac6d1', marker='o', markerfacecolor='white', label='$p(n)=\\\\frac{1}{n^{1.1}}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1_n11','mape')],0.05,axis=1), np.quantile(dict_results[('1_n11','mape')],0.95,axis=1), color='#8ac6d1', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('1_n','mape')],axis=1), c='#ff8080', marker='^', markerfacecolor='white', label='$p(n)=\\\\frac{1}{n}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1_n','mape')],0.05,axis=1), np.quantile(dict_results[('1_n','mape')],0.95,axis=1), color='#ff8080', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('logn2_n','mape')],axis=1), c='#ffba92', marker='P', markerfacecolor='white', label='$p(n)=\\\\frac{(\\\\log n)^2}{n}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('logn2_n','mape')],0.05,axis=1), np.quantile(dict_results[('logn2_n','mape')],0.95,axis=1), color='#ffba92', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('1','mape')],axis=1), c='#9394e7', marker='s', markerfacecolor='white', label='$p(n)=0.1$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1','mape')],0.05,axis=1), np.quantile(dict_results[('1','mape')],0.95,axis=1), color='#9394e7', alpha=0.1)\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel('Network size $n$')\n",
    "plt.ylabel('MAPE(%)')\n",
    "plt.ylim(0,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc36105-8d23-4f3c-b375-8f67fc4bdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size\n",
    "plt.plot(l_n, np.mean(dict_results[('1_n11','inv_deg')],axis=1), c='#8ac6d1', marker='o', markerfacecolor='white', label='$p(n)=\\\\frac{1}{n^{1.1}}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1_n11','inv_deg')],0.05,axis=1), np.quantile(dict_results[('1_n11','inv_deg')],0.95,axis=1), color='#8ac6d1', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('1_n','inv_deg')],axis=1), c='#ff8080', marker='^', markerfacecolor='white', label='$p(n)=\\\\frac{1}{n}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1_n','inv_deg')],0.05,axis=1), np.quantile(dict_results[('1_n','inv_deg')],0.95,axis=1), color='#ff8080', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('logn2_n','inv_deg')],axis=1), c='#ffba92', marker='P', markerfacecolor='white', label='$p(n)=\\\\frac{(\\\\log n)^2}{n}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('logn2_n','inv_deg')],0.05,axis=1), np.quantile(dict_results[('logn2_n','inv_deg')],0.95,axis=1), color='#ffba92', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('1','inv_deg')],axis=1), c='#9394e7', marker='s', markerfacecolor='white', label='$p(n)=0.1$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1','inv_deg')],0.05,axis=1), np.quantile(dict_results[('1','inv_deg')],0.95,axis=1), color='#9394e7', alpha=0.1)\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel('Network size $n$')\n",
    "plt.ylabel('Inverse in-degree density $\\mathcal{D}(G)$')\n",
    "plt.ylim(-0.01,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972f5ce-3757-4678-9359-ddcf5bebbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size\n",
    "plt.plot(l_n, np.mean(dict_results[('1_n11','mean_inv')],axis=1), c='#8ac6d1', marker='o', markerfacecolor='white', label='$p(n)=\\\\frac{1}{n^{1.1}}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1_n11','mean_inv')],0.05,axis=1), np.quantile(dict_results[('1_n11','mean_inv')],0.95,axis=1), color='#8ac6d1', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('1_n','mean_inv')],axis=1), c='#ff8080', marker='^', markerfacecolor='white', label='$p(n)=\\\\frac{1}{n}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1_n','mean_inv')],0.05,axis=1), np.quantile(dict_results[('1_n','mean_inv')],0.95,axis=1), color='#ff8080', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('logn2_n','mean_inv')],axis=1), c='#ffba92', marker='P', markerfacecolor='white', label='$p(n)=\\\\frac{(\\\\log n)^2}{n}$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('logn2_n','mean_inv')],0.05,axis=1), np.quantile(dict_results[('logn2_n','mean_inv')],0.95,axis=1), color='#ffba92', alpha=0.1)\n",
    "plt.plot(l_n, np.mean(dict_results[('1','mean_inv')],axis=1), c='#9394e7', marker='s', markerfacecolor='white', label='$p(n)=0.1$')\n",
    "plt.fill_between(l_n, np.quantile(dict_results[('1','mean_inv')],0.05,axis=1), np.quantile(dict_results[('1','mean_inv')],0.95,axis=1), color='#9394e7', alpha=0.1)\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel('Network size $n$')\n",
    "plt.ylabel('Inverse of mean in-degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55f43f-8440-4249-8464-4b8241a3fbc5",
   "metadata": {},
   "source": [
    "## __Figure 4__: Performance of ER graph (with varying network density) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86869c4a-d2b9-4ec8-bb08-60c41ef2d74f",
   "metadata": {},
   "source": [
    "### Generate one instance for each __additional__ ER graph parameter pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae059417-29fe-4e0a-8f0b-af71227349e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "for pn in l_pn2:\n",
    "    for i in range(1,rep+1):\n",
    "        sim_id = f'ER_{pn}/n{n}_{i}'\n",
    "        os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "        params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                  'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                  'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                  'network_type': 'ER',\n",
    "                  'is_network_given':False, 'network_size': n, 'ER_prob':dict_density[pn](n), 'network_dir':'',\n",
    "                  'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4, 'value_dir':''\n",
    "                  }\n",
    "            \n",
    "        G = network(params)\n",
    "        sample = diffusion_simulation(G,params)\n",
    "        sample.start_diffusion()\n",
    "        sample.run_fixed_point()\n",
    "        sample.output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed168df-5079-4d24-9233-cca59b0ecbb6",
   "metadata": {},
   "source": [
    "### Calculate the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d35e0-005e-4132-8af8-6f58af8b4bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pn in l_pn2:\n",
    "    for i in range(1,rep+1):\n",
    "        print_metrics(f'ER_{pn}/n{n}_{i}', True)\n",
    "        print_metrics(f'ER_{pn}/n{n}_{i}', False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee40ac-1659-40b9-b535-10d70eca0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = dict()\n",
    "\n",
    "rec_mape, rec_inv_deg, rec_mean_inv = [], [], []\n",
    "for pn in l_pn:\n",
    "    mape, inv_deg, mean_inv  = [], [], []\n",
    "    for i in range(1,rep+1):\n",
    "        df = pd.read_csv(f'../instances/ER_{pn}/n{n}_{i}/metrics_no0.csv')\n",
    "        mape.append(df['mape'].values[0]*100)\n",
    "        inv_deg.append(df['inv_ind_density'].values[0])\n",
    "        mean_inv.append(1/df['d_mean'].values[0])\n",
    "    rec_mape.append(mape)\n",
    "    rec_inv_deg.append(inv_deg)\n",
    "    rec_mean_inv.append(mean_inv)\n",
    "\n",
    "dict_results[(n,'mape')] = rec_mape\n",
    "dict_results[(n,'inv_deg')] = rec_inv_deg\n",
    "dict_results[(n,'mean_inv')] = rec_mean_inv\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ffe6b-c813-49e5-9b66-c6f6515e4ff4",
   "metadata": {},
   "source": [
    "### Replicate Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05392c-610f-4659-b4d7-0d2806dacfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(dict_results[(n,'mape')])\n",
    "plt.xlabel('Edge probability $p(n)$')\n",
    "plt.ylabel('MAPE(%)')\n",
    "plt.xticks([1,2,3,4,5,6,7],['$\\\\frac{1}{n^{1.3}}$', '$\\\\frac{1}{n^{1.1}}$', '$\\\\frac{1}{n}$', '$\\\\frac{\\\\sqrt{\\\\log{n}}}{n}$', '$\\\\frac{\\\\log{n}}{n}$','$\\\\frac{(\\\\log{n})^2}{n}$', '$0.1$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1818f0-b241-4fe4-8480-bc34ddb95f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(dict_results[(n,'inv_deg')])\n",
    "plt.xlabel('Edge probability $p(n)$')\n",
    "plt.ylabel('Inverse in-degree density $\\mathcal{D}(G)$')\n",
    "plt.xticks([1,2,3,4,5,6,7],['$\\\\frac{1}{n^{1.3}}$', '$\\\\frac{1}{n^{1.1}}$', '$\\\\frac{1}{n}$', '$\\\\frac{\\\\sqrt{\\\\log{n}}}{n}$', '$\\\\frac{\\\\log{n}}{n}$','$\\\\frac{(\\\\log{n})^2}{n}$', '$0.1$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a537ed5-a774-43ab-9fb5-feac35b773f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(dict_results[(n,'mean_inv')])\n",
    "plt.xlabel('Edge probability $p(n)$')\n",
    "plt.ylabel('Inverse of mean in-degree')\n",
    "plt.xticks([1,2,3,4,5,6,7],['$\\\\frac{1}{n^{1.3}}$', '$\\\\frac{1}{n^{1.1}}$', '$\\\\frac{1}{n}$', '$\\\\frac{\\\\sqrt{\\\\log{n}}}{n}$', '$\\\\frac{\\\\log{n}}{n}$','$\\\\frac{(\\\\log{n})^2}{n}$', '$0.1$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44376e04-4bbd-4a7a-a855-5f34b84b8902",
   "metadata": {},
   "source": [
    "## __Table 1__: Efficiency of ER Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554a1e2-77fb-467e-ac61-f4475da327bd",
   "metadata": {},
   "source": [
    "### Generate one instance for each ER graph parameter pair __with trajectory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f4050-ff86-47b1-925f-6126e808c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = '1'\n",
    "for n in l_n:\n",
    "    for i in range(1,rep+1):\n",
    "        sim_id = f'ER_{pn}_keep_traj/n{n}_{i}'\n",
    "        os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "        params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                  'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                  'cnt_iter': 100000, 't_warmup':1000, 'is_traj':True, \n",
    "                  'network_type': 'ER',\n",
    "                  'is_network_given':False, 'network_size': n, 'ER_prob':0.1, 'network_dir':'',\n",
    "                  'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4, 'value_dir':''\n",
    "                 }\n",
    "        \n",
    "        G = network(params)\n",
    "        sample = diffusion_simulation(G,params)\n",
    "        sample.start_diffusion()\n",
    "        sample.run_fixed_point()\n",
    "        sample.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac327f-309c-423d-a20f-125c30ae9868",
   "metadata": {},
   "source": [
    "### Compute the efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c91037-280b-4d46-b3a4-a698476f4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in l_n:\n",
    "    print('Network size:', n)\n",
    "    t_fpa, t_p, t_sim = [], [], []\n",
    "    for i in range(1,rep+1):\n",
    "        sim_id = f'ER_1_keep_traj/n{n}_{i}'\n",
    "        df_traj = pd.read_csv(f'../instances/{sim_id}/results_traj.csv')\n",
    "        df = pd.read_csv(f'../instances/{sim_id}/results.csv')\n",
    "        mape = np.mean(np.abs(df['sim']-df['fp'])/df['sim'])\n",
    "        t = pd.read_csv(f'../instances/{sim_id}/t.csv')['fp'][0]\n",
    "        t_fpa.append(t)\n",
    "        \n",
    "        is_p = False\n",
    "        \n",
    "        for t in range(200):\n",
    "            t1 = t*500+1\n",
    "            if (np.mean(np.abs(df['sim']-df_traj[f'p_{t1}'])/df['sim']) < mape) and not is_p:\n",
    "                t_p.append(df_traj[f't_{t1}'][0])\n",
    "                is_p = True\n",
    "            if np.mean(np.abs(df['sim']-df_traj[f'sim_{t1}'])/df['sim']) < mape:\n",
    "                t_sim.append(df_traj[f't_{t1}'][0])\n",
    "                break\n",
    "\n",
    "    \n",
    "    print('FPA time:', np.mean(t_fpa))\n",
    "    print('A-ABS time:', np.mean(t_p))\n",
    "    print('Naive ABS time:', np.mean(t_sim))\n",
    "    print('=======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099ccb1-64fd-4406-92fe-d7d538885955",
   "metadata": {},
   "source": [
    "## __Table 2__: Real-world network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184763e3-3475-4c70-b33e-a4d61f1ee6c2",
   "metadata": {},
   "source": [
    "### Construct real-world network edge information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d48404-ec04-4121-a312-29bbfea098e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    network_name = dict_real[real]\n",
    "    os.makedirs(f'../instances/{real}', exist_ok=True)\n",
    "    df = pd.read_csv(f'../instances/{network_name}.txt',sep=' ', names=['from_edge', 'to_edge'])\n",
    "    df_1 = df.copy()\n",
    "    df_1['from_edge'], df_1['to_edge'] = df['to_edge'], df['from_edge']\n",
    "    # build a undirected graph\n",
    "    pd.concat([df,df_1], ignore_index=True).to_csv(f'../instances/{real}/edge.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499ad7d-0380-4354-a324-946eca8f6963",
   "metadata": {},
   "source": [
    "### Generate one instance for each real-world network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99acaf0-1926-4ac8-8c81-94eeb20b16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    for i in range(1,rep+1):\n",
    "        sim_id = f'{real}/sim_{i}'\n",
    "        os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "        params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                  'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                  'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                  'is_network_given':True, 'network_dir':f'../instances/{real}/edge.csv',\n",
    "                  'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4\n",
    "                 }\n",
    "        \n",
    "        G = network(params)\n",
    "        sample = diffusion_simulation(G,params)\n",
    "        sample.start_diffusion()\n",
    "        sample.run_fixed_point()\n",
    "        sample.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9cd57-1315-4c01-8a1f-5365d5f6ad87",
   "metadata": {},
   "source": [
    "### Calculate the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa15b4c-3c92-4d85-acca-6697dc35ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    for i in range(1,rep+1):\n",
    "        print_metrics(f'{real}/sim_{i}', False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde52791-4069-4834-868f-a9d09cad064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    print('Real-world network:', real)\n",
    "    mape = []\n",
    "    for i in range(1,rep+1):\n",
    "        sim_id = f'{real}/sim_{i}'\n",
    "        df = pd.read_csv(f'../instances/{sim_id}/metrics.csv')\n",
    "        mape.append(df['mape'].values[0])\n",
    "    \n",
    "    print('n:', df['n'].values[0])\n",
    "    print('dmin:', df['d_min'].values[0])\n",
    "    print('dmax:', df['d_max'].values[0])\n",
    "    print('dbar:', df['d_mean'].values[0])\n",
    "    print('D(G):', df['inv_ind_density'].values[0])\n",
    "    print('mape:', np.mean(mape))\n",
    "    print('=======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d8070-36f3-4ae2-9496-583e31bd8be0",
   "metadata": {},
   "source": [
    "### Compute the efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85525fc2-facf-4b56-878f-23a44533466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    for i in range(1,rep+1):\n",
    "        sim_id = f'{real}_keep_traj/sim_{i}'\n",
    "        os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "        params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                  'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                  'cnt_iter': 100000, 't_warmup':1000, 'is_traj':True, \n",
    "                  'network_type': 'ER',\n",
    "                  'is_network_given':True, 'network_dir':f'../instances/{real}/edge.csv',\n",
    "                  'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4\n",
    "                 }\n",
    "        \n",
    "        G = network(params)\n",
    "        sample = diffusion_simulation(G,params)\n",
    "        sample.start_diffusion()\n",
    "        sample.run_fixed_point()\n",
    "        sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d956c65-823a-48f0-bd65-e253a5e84492",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    print('Network:', real)\n",
    "    \n",
    "    sim_id = f'{real}_keep_traj/sim_{i}'\n",
    "    df_traj = pd.read_csv(f'../instances/{sim_id}/results_traj.csv')\n",
    "    df = pd.read_csv(f'../instances/{sim_id}/results.csv')\n",
    "    mape = np.mean(np.abs(df['sim']-df['fp'])/df['sim'])\n",
    "    t = pd.read_csv(f'../instances/{sim_id}/t.csv')['fp'][0]\n",
    "    print('FPA time:', t)\n",
    "    \n",
    "    is_p = False\n",
    "    \n",
    "    for t in range(200):\n",
    "        t1 = t*500+1\n",
    "        if (np.mean(np.abs(df['sim']-df_traj[f'p_{t1}'])/df['sim']) < mape) and not is_p:\n",
    "            print('A-ABS time:', df_traj[f't_{t1}'][0])\n",
    "            is_p = True\n",
    "        if np.mean(np.abs(df['sim']-df_traj[f'sim_{t1}'])/df['sim']) < mape:\n",
    "            print('Naive ABS time:', df_traj[f't_{t1}'][0])\n",
    "            break\n",
    "    print('=======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f52560-99f6-4e70-8c65-e7e87f001d9c",
   "metadata": {},
   "source": [
    "## __Figure 5__: FPA performance vs $\\mathcal{D}(G)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5cc3f6-2276-4f7e-ad48-22e76a3a1b73",
   "metadata": {},
   "source": [
    "### Generate one instance for each power-law graph parameter pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377969e-0776-4f8f-9a29-cb6bc1532847",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = '0'\n",
    "for alpha in l_alpha:\n",
    "    for n in l_n:\n",
    "        for i in range(1,rep+1):\n",
    "            sim_id = f'PL_alpha{alpha}_theta{theta}/n{n}_{i}'\n",
    "            os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "            params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                      'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                      'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                      'network_type': 'PL',\n",
    "                      'is_network_given':False, 'network_size': n, 'PL_exponent':dict_alpha[alpha], 'PL_corr':0, 'PL_xmin':2, 'network_dir':'',\n",
    "                      'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4, 'value_dir':''\n",
    "                     }\n",
    "            \n",
    "            G = network(params)\n",
    "            sample = diffusion_simulation(G,params)\n",
    "            sample.start_diffusion()\n",
    "            sample.run_fixed_point()\n",
    "            sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53639cf7-3f2c-4f49-83fc-504e1b85b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = '25'\n",
    "for theta in l_theta:\n",
    "    for n in l_n:\n",
    "        for i in range(1,rep+1):\n",
    "            sim_id = f'PL_alpha{alpha}_theta{theta}/n{n}_{i}'\n",
    "            os.makedirs(f'../instances/{sim_id}', exist_ok=True)\n",
    "            params = {'sim_id':sim_id, 'alpha':0.1, 'beta':3.5,\n",
    "                      'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                      'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                      'network_type': 'PL',\n",
    "                      'is_network_given':False, 'network_size': n, 'PL_exponent':2.5, 'PL_corr':dict_theta[theta], 'PL_xmin':2, 'network_dir':'',\n",
    "                      'is_value_given':False, 'v_dist':'uniform_neg', 'v_dist_param': 4, 'value_dir':''\n",
    "                     }\n",
    "            \n",
    "            G = network(params)\n",
    "            sample = diffusion_simulation(G,params)\n",
    "            sample.start_diffusion()\n",
    "            sample.run_fixed_point()\n",
    "            sample.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebb6fb-540b-47a8-9dfb-083aa3116571",
   "metadata": {},
   "source": [
    "### Calculate the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd0964-8755-4ef1-8381-e68d0f5cdb53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for alpha in l_alpha:\n",
    "    for n in l_n:\n",
    "        for i in range(1,rep+1):\n",
    "            print_metrics(f'PL_alpha{alpha}_theta0/n{n}_{i}', False)\n",
    "for theta in l_theta:\n",
    "    for n in l_n:\n",
    "        for i in range(1,rep+1):\n",
    "            print_metrics(f'PL_alpha25_theta{theta}/n{n}_{i}', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3902e5-04b9-4e0f-bb7f-4d7bda26d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = dict()\n",
    "\n",
    "rec_mape, rec_inv_deg = [], []\n",
    "for real in l_real:\n",
    "    mape, inv_deg  = [], []\n",
    "    for i in range(1,rep+1):\n",
    "        df = pd.read_csv(f'../instances/{real}/sim_{i}/metrics.csv')\n",
    "        mape.append(df['mape'].values[0]*100)\n",
    "        inv_deg.append(df['inv_ind_density'].values[0])\n",
    "    rec_mape.append(mape)\n",
    "    rec_inv_deg.append(inv_deg)\n",
    "\n",
    "dict_results[('real','mape')] = rec_mape\n",
    "dict_results[('real','inv_deg')] = rec_inv_deg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d00ea9-7c53-41d3-a4b4-73743b5d8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn in l_pn1:\n",
    "    rec_mape, rec_inv_deg = [], []\n",
    "    for n in l_n:\n",
    "        mape, inv_deg  = [], []\n",
    "        for i in range(1,rep+1):\n",
    "            df = pd.read_csv(f'../instances/ER_{pn}/n{n}_{i}/metrics.csv')\n",
    "            mape.append(df['mape'].values[0]*100)\n",
    "            inv_deg.append(df['inv_ind_density'].values[0])\n",
    "        rec_mape.append(mape)\n",
    "        rec_inv_deg.append(inv_deg)\n",
    "\n",
    "    dict_results[(pn,'mape')] = rec_mape\n",
    "    dict_results[(pn,'inv_deg')] = rec_inv_deg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0481d6-30c3-4dc5-a296-dc7360cae54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "rec_mape, rec_inv_deg = [], []\n",
    "for pn in l_pn2:\n",
    "    mape, inv_deg  = [], []\n",
    "    for i in range(1,rep+1):\n",
    "        df = pd.read_csv(f'../instances/ER_{pn}/n{n}_{i}/metrics.csv')\n",
    "        mape.append(df['mape'].values[0]*100)\n",
    "        inv_deg.append(df['inv_ind_density'].values[0])\n",
    "    rec_mape.append(mape)\n",
    "    rec_inv_deg.append(inv_deg)\n",
    "\n",
    "dict_results[(n,'mape')] = rec_mape\n",
    "dict_results[(n,'inv_deg')] = rec_inv_deg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee846b-90ac-44d3-8446-a6a5b4de1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = '0'\n",
    "\n",
    "for alpha in l_alpha:\n",
    "    rec_mape, rec_inv_deg = [], []\n",
    "    for n in l_n:\n",
    "        mape, inv_deg  = [], []\n",
    "        for i in range(1,rep+1):\n",
    "            df = pd.read_csv(f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/metrics.csv')\n",
    "            mape.append(df['mape'].values[0]*100)\n",
    "            inv_deg.append(df['inv_ind_density'].values[0])\n",
    "        rec_mape.append(mape)\n",
    "        rec_inv_deg.append(inv_deg)\n",
    "\n",
    "    dict_results[(alpha,'mape')] = rec_mape\n",
    "    dict_results[(alpha,'inv_deg')] = rec_inv_deg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8b2bc-36e1-487f-a528-b968c594359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = '25'\n",
    "\n",
    "for theta in l_theta:\n",
    "    rec_mape, rec_inv_deg = [], []\n",
    "    for n in l_n:\n",
    "        mape, inv_deg  = [], []\n",
    "        for i in range(1,rep+1):\n",
    "            df = pd.read_csv(f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/metrics.csv')\n",
    "            mape.append(df['mape'].values[0]*100)\n",
    "            inv_deg.append(df['inv_ind_density'].values[0])\n",
    "        rec_mape.append(mape)\n",
    "        rec_inv_deg.append(inv_deg)\n",
    "\n",
    "    dict_results[(theta,'mape')] = rec_mape\n",
    "    dict_results[(theta,'inv_deg')] = rec_inv_deg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e93fb1-f02e-4123-9ea0-fdbf165da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.mean(dict_results[('real','inv_deg')],axis=1), np.mean(dict_results[('real','mape')],axis=1), c='#8ac6d1', marker='o', edgecolor='white', s=60, label='real world networks')\n",
    "plt.scatter(np.mean(dict_results[('1_n11','inv_deg')],axis=1), np.mean(dict_results[('1_n11','mape')],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60, label='ER networks')\n",
    "plt.scatter(np.mean(dict_results[('1_n','inv_deg')],axis=1), np.mean(dict_results[('1_n','mape')],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('logn2_n','inv_deg')],axis=1), np.mean(dict_results[('logn2_n','mape')],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('1','inv_deg')],axis=1), np.mean(dict_results[('1','mape')],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[(1000,'inv_deg')],axis=1), np.mean(dict_results[(1000,'mape')],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('25','inv_deg')],axis=1), np.mean(dict_results[('25','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60, label='PL networks')\n",
    "plt.scatter(np.mean(dict_results[('30','inv_deg')],axis=1), np.mean(dict_results[('30','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('35','inv_deg')],axis=1), np.mean(dict_results[('35','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('neg05','inv_deg')],axis=1), np.mean(dict_results[('neg05','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('pos05','inv_deg')],axis=1), np.mean(dict_results[('pos05','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('neg10','inv_deg')],axis=1), np.mean(dict_results[('neg10','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('pos10','inv_deg')],axis=1), np.mean(dict_results[('pos10','mape')],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "\n",
    "plt.xlabel('Inverse in-degree density $\\\\mathcal{D}(G)$')\n",
    "plt.ylabel('MAPE(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af3b16-f5ca-4bcf-930f-79f58839ff24",
   "metadata": {},
   "source": [
    "## __Figure 6__: Mixture ccheme with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b4b11-035c-4adf-8c50-662dde3e3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in l_real:\n",
    "    for t_iter in l_t_iter:\n",
    "        for i in range(1,rep+1):\n",
    "            os.makedirs(f'../instances/{real}_re_cal_{t_iter}/sim_{i}', exist_ok=True)\n",
    "            params = {'sim_id':f'{real}_re_cal_{t_iter}/sim_{i}', 'alpha':0.1, 'beta':3.5,\n",
    "                      'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                      'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                      'network_type': 'ER',\n",
    "                      'is_network_given':True, 'network_dir':f'../instances/{real}/sim_{i}/edge.csv',\n",
    "                      'is_value_given':True, 'value_dir':f'../instances/{real}/sim_{i}/v.csv'\n",
    "                     }\n",
    "            \n",
    "            G = network(params)\n",
    "            sample = diffusion_simulation(G,params)\n",
    "            sample.run_fixed_point()\n",
    "            sample.re_cal(t_iter = t_iter)\n",
    "            sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20271252-5dff-4f39-a768-0c0acabcca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = dict()\n",
    "\n",
    "for real in ['caltech', 'amherst']:\n",
    "    for t_iter in l_t_iter:\n",
    "        rec_mape_re_cal = []\n",
    "        for d in range(200):\n",
    "            mape = []\n",
    "            for i in range(1,rep+1):\n",
    "                df = pd.read_csv(f'../instances/{real}/sim_{i}/results.csv')\n",
    "                df_re_cal = pd.read_csv(f'../instances/{real}_re_cal_{t_iter}/sim_{i}/results.csv')\n",
    "                if len(df)>len(df_re_cal):\n",
    "                    df = df[:len(df_re_cal)]\n",
    "                diff = (np.abs(df['sim']-df['fp'])/df['sim']).values\n",
    "                diff_re_cal = (np.abs(df['sim']-df_re_cal['p_re'])/df['sim']).values\n",
    "                not_low_deg = (df_re_cal['in_deg']>d).values\n",
    "                diff_re_cal[not_low_deg] =  diff[not_low_deg]\n",
    "                mape.append(np.mean(diff_re_cal)*100)\n",
    "            rec_mape_re_cal.append(mape)\n",
    "        dict_results[(real,'mix', t_iter)] = rec_mape_re_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a710ce-85b4-4226-9e1a-383089951eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(200), np.mean(dict_results[('caltech','mix', 100)], axis=1), c='#8ac6d1', label = 'Sample size=100')\n",
    "plt.plot(range(200), np.mean(dict_results[('caltech','mix', 1000)], axis=1), c='#ff8080', linestyle='--', label = 'Sample size=1000')\n",
    "plt.fill_between(range(200), np.quantile(dict_results[('caltech','mix', 100)], 0.05, axis=1), np.quantile(dict_results[('caltech','mix', 100)], 0.95, axis=1), color='#8ac6d1', alpha=0.1)\n",
    "plt.fill_between(range(200), np.quantile(dict_results[('caltech','mix', 1000)], 0.05, axis=1), np.quantile(dict_results[('caltech','mix', 1000)], 0.95, axis=1), color='#ff8080', alpha=0.1)\n",
    "plt.xlabel('Cutoff in-degree')\n",
    "plt.ylabel('MAPE(%)')\n",
    "plt.xlim(-5,200)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac104a6-3109-4c1a-b63f-9260ceece6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(200), np.mean(dict_results[('amherst','mix', 100)], axis=1), c='#8ac6d1', label = 'Sample size=100')\n",
    "plt.plot(range(200), np.mean(dict_results[('amherst','mix', 1000)], axis=1), c='#ff8080', linestyle='--', label = 'Sample size=1000')\n",
    "plt.fill_between(range(200), np.quantile(dict_results[('amherst','mix', 100)], 0.05, axis=1), np.quantile(dict_results[('amherst','mix', 100)], 0.95, axis=1), color='#8ac6d1', alpha=0.1)\n",
    "plt.fill_between(range(200), np.quantile(dict_results[('amherst','mix', 1000)], 0.05, axis=1), np.quantile(dict_results[('amherst','mix', 1000)], 0.95, axis=1), color='#ff8080', alpha=0.1)\n",
    "plt.xlabel('Cutoff in-degree')\n",
    "plt.ylabel('MAPE(%)')\n",
    "plt.xlim(-5,200)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b75d3-0a51-4a0d-838e-b0e6ae24f835",
   "metadata": {},
   "source": [
    "## __Figure 7__: Mixture Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79088d24-a650-4c56-80d4-2d01a1d092f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in l_n:\n",
    "    for pn in l_pn1:\n",
    "        for t_iter in l_t_iter:\n",
    "            for i in range(1,rep+1):\n",
    "                os.makedirs(f'../instances/ER_{pn}_re_cal_{t_iter}/n{n}_{i}', exist_ok=True)\n",
    "                params = {'sim_id':f'ER_{pn}_re_cal_{t_iter}/n{n}_{i}', 'alpha':0.1, 'beta':3.5,\n",
    "                          'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                          'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                          'network_type': 'ER',\n",
    "                          'is_network_given':True, 'network_dir':f'../instances/ER_{pn}/n{n}_{i}/edge.csv',\n",
    "                          'is_value_given':True, 'value_dir':f'../instances/ER_{pn}/n{n}_{i}/v.csv'\n",
    "                         }\n",
    "                \n",
    "                G = network(params)\n",
    "                sample = diffusion_simulation(G,params)\n",
    "                sample.run_fixed_point()\n",
    "                sample.re_cal(t_iter = t_iter)\n",
    "                sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b58e1b-92c6-4d7b-81c8-3ba6af8a10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "for pn in l_pn2:\n",
    "    for t_iter in l_t_iter:\n",
    "        for i in range(1,rep+1):\n",
    "            os.makedirs(f'../instances/ER_{pn}_re_cal_{t_iter}/n{n}_{i}', exist_ok=True)\n",
    "            params = {'sim_id':f'ER_{pn}_re_cal_{t_iter}/n{n}_{i}', 'alpha':0.1, 'beta':3.5,\n",
    "                      'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                      'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                      'network_type': 'ER',\n",
    "                      'is_network_given':True, 'network_dir':f'../instances/ER_{pn}/n{n}_{i}/edge.csv',\n",
    "                      'is_value_given':True, 'value_dir':f'../instances/ER_{pn}/n{n}_{i}/v.csv'\n",
    "                      }\n",
    "                \n",
    "            G = network(params)\n",
    "            sample = diffusion_simulation(G,params)\n",
    "            sample.run_fixed_point()\n",
    "            sample.re_cal(t_iter = t_iter)\n",
    "            sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e8573-7ef2-4e81-ac54-a3cbdd75a893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = '25'\n",
    "for theta in l_theta:\n",
    "    for n in l_n:\n",
    "        for t_iter in l_t_iter:\n",
    "            for i in range(1,rep+1):\n",
    "                os.makedirs(f'../instances/PL_alpha{alpha}_theta{theta}_re_cal_{t_iter}/n{n}_{i}', exist_ok=True)\n",
    "                params = {'sim_id':f'PL_alpha{alpha}_theta{theta}_re_cal_{t_iter}/n{n}_{i}', 'alpha':0.1, 'beta':3.5,\n",
    "                          'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                          'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                          'network_type': 'PL',\n",
    "                          'is_network_given':True, 'network_dir':f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/edge.csv',\n",
    "                          'is_value_given':True, 'value_dir':f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/v.csv'\n",
    "                         }\n",
    "                \n",
    "                G = network(params)\n",
    "                sample = diffusion_simulation(G,params)\n",
    "                sample.run_fixed_point()\n",
    "                sample.re_cal(t_iter = t_iter)\n",
    "                sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f421f-eec5-4a88-91b7-8843cb5eeac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta = '0'\n",
    "for alpha in l_alpha:\n",
    "    for n in l_n:\n",
    "        for t_iter in l_t_iter:\n",
    "            for i in range(1,rep+1):\n",
    "                os.makedirs(f'../instances/PL_alpha{alpha}_theta{theta}_re_cal_{t_iter}/n{n}_{i}', exist_ok=True)\n",
    "                params = {'sim_id':f'../instances/PL_alpha{alpha}_theta{theta}_re_cal_{t_iter}/n{n}_{i}', 'alpha':0.1, 'beta':3.5,\n",
    "                          'noise_dist': 'logistic', 'noise_dist_param':1,\n",
    "                          'cnt_iter': 100000, 't_warmup':1000, 'is_traj':False, \n",
    "                          'network_type': 'PL',\n",
    "                          'is_network_given':True, 'network_dir':f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/edge.csv',\n",
    "                          'is_value_given':True, 'value_dir':f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/v.csv'\n",
    "                         }\n",
    "                \n",
    "                G = network(params)\n",
    "                sample = diffusion_simulation(G,params)\n",
    "                sample.run_fixed_point()\n",
    "                sample.re_cal(t_iter = t_iter)\n",
    "                sample.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4b879-9c5a-4593-a5b8-d66a7b6184db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = dict()\n",
    "\n",
    "for t_iter in l_t_iter:\n",
    "    rec_mape, rec_mape_recal = [], []\n",
    "    if t_iter == 100:\n",
    "        d = 20\n",
    "    else:\n",
    "        d = 200\n",
    "    for real in l_real:\n",
    "        mape, mape_recal  = [], []\n",
    "        for i in range(1,rep+1):\n",
    "            df = pd.read_csv(f'../instances/{real}/sim_{i}/results.csv')\n",
    "            mape.append(np.mean(abs(df['sim']-df['fp'])/df['sim'])*100)\n",
    "                \n",
    "            df_re_cal = pd.read_csv(f'../instances/{real}_re_cal_{t_iter}/sim_{i}/results.csv')\n",
    "            if len(df)>len(df_re_cal):\n",
    "                df = df[:len(df_re_cal)]\n",
    "            diff = (np.abs(df['sim']-df['fp'])/df['sim']).values\n",
    "            diff_re_cal = (np.abs(df['sim']-df_re_cal['p_re'])/df['sim']).values\n",
    "            not_low_deg = (df_re_cal['in_deg']>d).values\n",
    "            diff_re_cal[not_low_deg] =  diff[not_low_deg]\n",
    "            mape_recal.append(np.mean(diff_re_cal)*100)\n",
    "        \n",
    "        rec_mape.append(mape)\n",
    "        rec_mape_recal.append(mape_recal)\n",
    "\n",
    "    dict_results[('real','fpa')] = rec_mape\n",
    "    dict_results[('real','mix', t_iter)] = rec_mape_recal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da30a5-3c48-4ec1-bf40-f75fb147b5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t_iter in l_t_iter:\n",
    "    if t_iter == 100:\n",
    "        d = 20\n",
    "    else:\n",
    "        d = 200\n",
    "    for pn in l_pn1:\n",
    "        rec_mape, rec_mape_recal = [], []\n",
    "        for n in l_n:\n",
    "            mape, mape_recal  = [], []\n",
    "            for i in range(1,rep+1):\n",
    "                df = pd.read_csv(f'../instances/ER_{pn}/n{n}_{i}/results.csv')\n",
    "                mape.append(np.mean(abs(df['sim']-df['fp'])/df['sim'])*100)\n",
    "                    \n",
    "                df_re_cal = pd.read_csv(f'../instances/ER_{pn}_re_cal_{t_iter}/n{n}_{i}/results.csv')\n",
    "                if len(df)>len(df_re_cal):\n",
    "                    df = df[:len(df_re_cal)]\n",
    "                diff = (np.abs(df['sim']-df['fp'])/df['sim']).values\n",
    "                diff_re_cal = (np.abs(df['sim']-df_re_cal['p_re'])/df['sim']).values\n",
    "                not_low_deg = (df_re_cal['in_deg']>d).values\n",
    "                diff_re_cal[not_low_deg] =  diff[not_low_deg]\n",
    "                mape_recal.append(np.mean(diff_re_cal)*100)\n",
    "                \n",
    "            rec_mape.append(mape)\n",
    "            rec_mape_recal.append(mape_recal)\n",
    "    \n",
    "        dict_results[(pn, 'fpa')] = rec_mape\n",
    "        dict_results[(pn, 'mix', t_iter)] = rec_mape_recal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc246d-f8fc-42d7-ac80-f3221f569351",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "for t_iter in l_t_iter:\n",
    "    if t_iter == 100:\n",
    "        d = 20\n",
    "    else:\n",
    "        d = 200\n",
    "    \n",
    "    rec_mape, rec_mape_recal = [], []\n",
    "    for pn in l_pn2:\n",
    "        mape, mape_recal  = [], []\n",
    "        for i in range(1,rep+1):\n",
    "            df = pd.read_csv(f'../instances/ER_{pn}/n{n}_{i}/results.csv')\n",
    "            mape.append(np.mean(abs(df['sim']-df['fp'])/df['sim'])*100)\n",
    "                    \n",
    "            df_re_cal = pd.read_csv(f'../instances/ER_{pn}_re_cal_{t_iter}/n{n}_{i}/results.csv')\n",
    "            if len(df)>len(df_re_cal):\n",
    "                df = df[:len(df_re_cal)]\n",
    "            diff = (np.abs(df['sim']-df['fp'])/df['sim']).values\n",
    "            diff_re_cal = (np.abs(df['sim']-df_re_cal['p_re'])/df['sim']).values\n",
    "            not_low_deg = (df_re_cal['in_deg']>d).values\n",
    "            diff_re_cal[not_low_deg] =  diff[not_low_deg]\n",
    "            mape_recal.append(np.mean(diff_re_cal)*100)\n",
    "                \n",
    "        rec_mape.append(mape)\n",
    "        rec_mape_recal.append(mape_recal)\n",
    "    \n",
    "    dict_results[(n, 'fpa')] = rec_mape\n",
    "    dict_results[(n, 'mix', t_iter)] = rec_mape_recal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ab886-f7ef-4d4c-9157-357672ba7f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta = '0'\n",
    "\n",
    "for t_iter in l_t_iter:\n",
    "    if t_iter == 100:\n",
    "        d = 20\n",
    "    else:\n",
    "        d = 200\n",
    "    for alpha in l_alpha:\n",
    "        rec_mape, rec_mape_recal = [], []\n",
    "        for n in l_n:\n",
    "            mape, mape_recal  = [], []\n",
    "            for i in range(1,rep+1):\n",
    "                df = pd.read_csv(f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/results.csv')\n",
    "                mape.append(np.mean(abs(df['sim']-df['fp'])/df['sim'])*100)\n",
    "                    \n",
    "                df_re_cal = pd.read_csv(f'../instances/PL_alpha{alpha}_theta{theta}_re_cal_{t_iter}/n{n}_{cnt}/results.csv')\n",
    "                if len(df)>len(df_re_cal):\n",
    "                    df = df[:len(df_re_cal)]\n",
    "                diff = (np.abs(df['sim']-df['fp'])/df['sim']).values\n",
    "                diff_re_cal = (np.abs(df['sim']-df_re_cal['p_re'])/df['sim']).values\n",
    "                not_low_deg = (df_re_cal['in_deg']>d).values\n",
    "                diff_re_cal[not_low_deg] =  diff[not_low_deg]\n",
    "                mape_recal.append(np.mean(diff_re_cal)*100)\n",
    "                \n",
    "            rec_mape.append(mape)\n",
    "            rec_mape_recal.append(mape_recal)\n",
    "    \n",
    "        dict_results[(alpha, 'fpa')] = rec_mape\n",
    "        dict_results[(alpha, 'mix', t_iter)] = rec_mape_recal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bdbde-b0d4-4f82-87f0-78a2ea0e5c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = '25'\n",
    "\n",
    "for t_iter in l_t_iter:\n",
    "    if t_iter == 100:\n",
    "        d = 20\n",
    "    else:\n",
    "        d = 200\n",
    "    for theta in l_theta:\n",
    "        rec_mape, rec_mape_recal = [], []\n",
    "        for n in l_n:\n",
    "            mape, mape_recal  = [], []\n",
    "            for i in range(1,rep+1):\n",
    "                df = pd.read_csv(f'../instances/PL_alpha{alpha}_theta{theta}/n{n}_{i}/results.csv')\n",
    "                mape.append(np.mean(abs(df['sim']-df['fp'])/df['sim'])*100)\n",
    "                    \n",
    "                df_re_cal = pd.read_csv(f'../instances/PL_alpha{alpha}_theta{theta}_re_cal_{t_iter}/n{n}_{i}/results.csv')\n",
    "                if len(df)>len(df_re_cal):\n",
    "                    df = df[:len(df_re_cal)]\n",
    "                diff = (np.abs(df['sim']-df['fp'])/df['sim']).values\n",
    "                diff_re_cal = (np.abs(df['sim']-df_re_cal['p_re'])/df['sim']).values\n",
    "                not_low_deg = (df_re_cal['in_deg']>d).values\n",
    "                diff_re_cal[not_low_deg] =  diff[not_low_deg]\n",
    "                mape_recal.append(np.mean(diff_re_cal)*100)\n",
    "                \n",
    "            rec_mape.append(mape)\n",
    "            rec_mape_recal.append(mape_recal)\n",
    "    \n",
    "        dict_results[(theta, 'fpa')] = rec_mape\n",
    "        dict_results[(theta, 'mix', t_iter)] = rec_mape_recal\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a65110-530c-4839-8fbf-c945a3412b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_iter = 100\n",
    "\n",
    "plt.scatter(np.mean(dict_results[('real','fpa')],axis=1), np.mean(dict_results[('real','mix', t_iter)],axis=1), c='#8ac6d1', marker='o', edgecolor='white', s=60, label='real world networks')\n",
    "plt.scatter(np.mean(dict_results[('1_n11','fpa')],axis=1), np.mean(dict_results[('1_n11','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60, label='ER networks')\n",
    "plt.scatter(np.mean(dict_results[('1_n','fpa')],axis=1), np.mean(dict_results[('1_n','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('logn2_n','fpa')],axis=1), np.mean(dict_results[('logn2_n','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('1','fpa')],axis=1), np.mean(dict_results[('1','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[(1000,'fpa')],axis=1), np.mean(dict_results[(1000,'mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('25','fpa')],axis=1), np.mean(dict_results[('25','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60, label='PL networks')\n",
    "plt.scatter(np.mean(dict_results[('30','fpa')],axis=1), np.mean(dict_results[('30','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('35','fpa')],axis=1), np.mean(dict_results[('35','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('neg05','fpa')],axis=1), np.mean(dict_results[('neg05','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('pos05','fpa')],axis=1), np.mean(dict_results[('pos05','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('neg10','fpa')],axis=1), np.mean(dict_results[('neg10','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('pos10','fpa')],axis=1), np.mean(dict_results[('pos10','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.plot([0,18],[0,18],c='gray', linestyle='--')\n",
    "\n",
    "plt.xlabel('MAPE(%) - the FPA scheme')\n",
    "plt.ylabel('MAPE(%) - the mixture scheme')\n",
    "plt.xlim(0,18)\n",
    "plt.ylim(0,18)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d287ee-4d3f-477b-9789-c89fe70f69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_iter = 1000\n",
    "\n",
    "plt.scatter(np.mean(dict_results[('real','fpa')],axis=1), np.mean(dict_results[('real','mix', t_iter)],axis=1), c='#8ac6d1', marker='o', edgecolor='white', s=60, label='real world networks')\n",
    "plt.scatter(np.mean(dict_results[('1_n11','fpa')],axis=1), np.mean(dict_results[('1_n11','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60, label='ER networks')\n",
    "plt.scatter(np.mean(dict_results[('1_n','fpa')],axis=1), np.mean(dict_results[('1_n','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('logn2_n','fpa')],axis=1), np.mean(dict_results[('logn2_n','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('1','fpa')],axis=1), np.mean(dict_results[('1','mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[(1000,'fpa')],axis=1), np.mean(dict_results[(1000,'mix', t_iter)],axis=1), c='#ff8080', marker='^', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('25','fpa')],axis=1), np.mean(dict_results[('25','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60, label='PL networks')\n",
    "plt.scatter(np.mean(dict_results[('30','fpa')],axis=1), np.mean(dict_results[('30','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('35','fpa')],axis=1), np.mean(dict_results[('35','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('neg05','fpa')],axis=1), np.mean(dict_results[('neg05','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('pos05','fpa')],axis=1), np.mean(dict_results[('pos05','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('neg10','fpa')],axis=1), np.mean(dict_results[('neg10','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.scatter(np.mean(dict_results[('pos10','fpa')],axis=1), np.mean(dict_results[('pos10','mix', t_iter)],axis=1), c='#ffba92', marker='D', edgecolor='white', s=60)\n",
    "plt.plot([0,18],[0,18],c='gray', linestyle='--')\n",
    "\n",
    "plt.xlabel('MAPE(%) - the FPA scheme')\n",
    "plt.ylabel('MAPE(%) - the mixture scheme')\n",
    "plt.xlim(0,18)\n",
    "plt.ylim(0,18)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3a873-b32a-41e5-8417-6a6db634cd90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
